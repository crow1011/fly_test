# Описание работы

DAG состоит из трех частей:
 - Забирает dataset титаник и сохраняет его в файл titanic.csv, этап Extract
 - Читает titanic.csv, оставляет только выживших и сохраняет в файл titanic_survived.csv, этап Transform
 - Читает titanic_survived.csv и отправляет его в db sqlite

Задание подобрал, чтобы лучше разобраться в ETL. В проде бы использовал и базы другие, да и надо использованием ресурсов надо подумать хорошо. С Apache Airflow раньше не работал, но очень полезный, в любом случае возьму на изучение.